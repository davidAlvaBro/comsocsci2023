{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes in list of authorIds and outputs the corresponding top fields in the same order \n",
    "def author_field(ids, df_author):\n",
    "    \"\"\"\n",
    "    Compute the top field of the given authors \n",
    "\n",
    "    Args:\n",
    "        ids (list): containing the ids of the authors in question\n",
    "        df_author (pandas df): data frame of type author that contains the given ids \n",
    "    \n",
    "    return: \n",
    "        fields (list): list of top fields of the given authors \n",
    "\n",
    "    \"\"\"\n",
    "    # Get boolean array that indicates where the authors are \n",
    "    mask = df_author[\"id\"].isin(ids)\n",
    "    \n",
    "    # Get the fields \n",
    "    fields = list(df_author[\"field\"][mask]) \n",
    "    \n",
    "    return fields \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argument_paper_dataframe(df_papers, df_author):\n",
    "    \"\"\"\n",
    "    Takes in a paper data frame, arguments it with a new column and puts the fields of the author in that column.\n",
    "\n",
    "    Args:\n",
    "        df_papers (pandas dataframe): paper dataframe (like before)\n",
    "        df_author (pandas dataframe): author dataframe (like before)\n",
    "\n",
    "    Returns:\n",
    "        df_papers (pandas dataframe): the dataframe from before, argumentet with the new column\n",
    "    \"\"\"\n",
    "    df_papers[\"author_field\"] = None \n",
    "\n",
    "    for index, row in tqdm(df_papers.iterrows()):\n",
    "        # Currently authors are stored as a string representation of the list so we make it a list again \n",
    "        authors = ast.literal_eval(row[\"authors\"]) \n",
    "        # Now we need to turn the authors into a list of integers, because the df_paper dataframe stores them as such \n",
    "        authors = [eval(id) for id in authors if id is not None]\n",
    "        #authors = [eval(id) for id in authors]\n",
    "        # Find the fields of the authors \n",
    "        authors_fields = author_field(authors, df_author=df_author)\n",
    "        df_papers[\"author_field\"][index] = authors_fields\n",
    "        # print(authors_fields) # debugging \n",
    "    # print(df_papers.head()) # debugging \n",
    "        \n",
    "    return df_papers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the paper datafram to a social science dataframe\n",
    "def generate_CCS_papers_1(df_papers, social_science_fields, quantitative_fields, verbose=False):\n",
    "    \n",
    "    rows_to_drop = []\n",
    "    \n",
    "    # Drop rows that are before 2008\n",
    "    for index, row in tqdm(df_papers.iterrows()):\n",
    "        if row[\"year\"] < 2008: \n",
    "            rows_to_drop.append(index)\n",
    "    if verbose: print(f\"{len(rows_to_drop)} papers removed because they were to old. ({len(rows_to_drop)/len(df_papers)*100:.0f}%)\")\n",
    "    df_papers.drop(index=rows_to_drop, inplace=True) \n",
    "    rows_to_drop = []\n",
    "    \n",
    "        \n",
    "    # Drop rows that do not contain a DOI\n",
    "    for index, row in df_papers.iterrows():\n",
    "        if row[\"doi\"] == None: \n",
    "            rows_to_drop.append(index)\n",
    "        else: \n",
    "            try:\n",
    "                ast.literal_eval(row[\"doi\"])[0][\"DOI\"]\n",
    "            except: \n",
    "                rows_to_drop.append(index)\n",
    "    if verbose: print(f\"{len(rows_to_drop)} papers removed because they did not have a DOI. ({len(rows_to_drop)/len(df_papers)*100:.0f}%)\")\n",
    "    df_papers.drop(index=rows_to_drop, inplace=True) \n",
    "    rows_to_drop = []\n",
    "    \n",
    "    # Drop paper if it includes biology\n",
    "    for index, row in df_papers.iterrows():\n",
    "        # Go through the entire list of fields for each paper \n",
    "        for field in ast.literal_eval(row[\"field\"]):\n",
    "            if field[\"category\"] == \"Biology\":\n",
    "                rows_to_drop.append(index)\n",
    "    if verbose: print(f\"{len(rows_to_drop)} papers removed because biology was in the field. ({len(rows_to_drop)/len(df_papers)*100:.0f}%)\")\n",
    "    df_papers.drop(index=rows_to_drop, inplace=True) \n",
    "    rows_to_drop = []\n",
    "    \n",
    "    # Drop paper if the fields are not not included in social science fields\n",
    "    for index, row in df_papers.iterrows():\n",
    "        is_in_SCF = False \n",
    "        # Go through the entire list of fields for each paper \n",
    "        for field in ast.literal_eval(row[\"field\"]):\n",
    "            if field[\"category\"] in social_science_fields:\n",
    "                is_in_SCF = True\n",
    "        \n",
    "        # if the paper was not in social science fields drop it \n",
    "        if not is_in_SCF: \n",
    "            rows_to_drop.append(index)\n",
    "    if verbose: print(f\"{len(rows_to_drop)} papers removed because thier fields not in Social Science Fields. ({len(rows_to_drop)/len(df_papers)*100:.0f}%)\")\n",
    "    df_papers.drop(index=rows_to_drop, inplace=True) \n",
    "    rows_to_drop = []\n",
    "    \n",
    "    return df_papers\n",
    "\n",
    "\n",
    "# It is time consuming to add a row in the dataframe, hence it helps that the dataframe is 100 times smaller \n",
    "def generate_CCS_papers_2(df_papers, social_science_fields, quantitative_fields, verbose=False):\n",
    "    \n",
    "    rows_to_drop = []\n",
    "    \n",
    "    # Drop the papers with more than 9 Computational Social Science authors? TODO what does she mean! \n",
    "    for index, row in df_papers.iterrows():\n",
    "        if len(row[\"author_field\"]) > 9: # Count authors, should I check if they are in the author data frame? That's gonna take a while\n",
    "            rows_to_drop.append(index)\n",
    "    if verbose: print(f\"{len(rows_to_drop)} papers removed because there are more than 9 CSS authors. ({len(rows_to_drop)/len(df_papers)*100:.0f}%)\")\n",
    "    df_papers.drop(index=rows_to_drop, inplace=True) \n",
    "    rows_to_drop = []\n",
    "    \n",
    "    # Drop paper if the fields are not not included in quantitative data and authors aren't either\n",
    "    for index, row in df_papers.iterrows():\n",
    "        is_in_SCF = False \n",
    "        # Go through the entire list of fields for each paper \n",
    "        for field in ast.literal_eval(row[\"field\"]):\n",
    "            if field[\"category\"] in quantitative_fields:\n",
    "                is_in_SCF = True\n",
    "        \n",
    "        # Check if the authors are in the quantitative_fields\n",
    "        for author_field in row[\"author_field\"]: \n",
    "            if author_field in quantitative_fields: \n",
    "                is_in_SCF = True\n",
    "       \n",
    "        # if the paper was not in social science fields drop it \n",
    "        if not is_in_SCF: \n",
    "            rows_to_drop.append(index)\n",
    "    if verbose: print(f\"{len(rows_to_drop)} papers removed because thier fields and authors are not in Quantitative Fields. ({len(rows_to_drop)/len(df_papers)*100:.0f}%)\")\n",
    "    df_papers.drop(index=rows_to_drop, inplace=True) \n",
    "    rows_to_drop = []\n",
    "    \n",
    "    return df_papers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initially we have 1078817 papers.\n",
      "302900 papers removed because they were to old. (28%)\n",
      "148196 papers removed because they did not have a DOI. (19%)\n",
      "122867 papers removed because biology was in the field. (20%)\n",
      "466782 papers removed because thier fields not in Social Science Fields. (92%)\n",
      "There are 38072 papers left of 1078817 which is 3.53%\n"
     ]
    }
   ],
   "source": [
    "# Heuristic \n",
    "social_science_fields = {\"Political Science\", \"Sociology\", \"Economics\"}\n",
    "quantitative_fields = {\"Mathematics\", \"Physics\", \"Computer Science\"}\n",
    "\n",
    "# Load dataframes\n",
    "df_author = pd.read_csv(\"df_author.csv\")\n",
    "df_papers = pd.read_csv(\"df_paper.csv\")\n",
    "\n",
    "# Drop papers, but not based on the authors\n",
    "n_papers_before = len(df_papers)\n",
    "\n",
    "print(f\"Initially we have {n_papers_before} papers.\")\n",
    "df_papers = generate_CCS_papers_1(df_papers, social_science_fields, quantitative_fields, verbose=True)\n",
    "\n",
    "# Papers removed so far \n",
    "print(f\"There are {len(df_papers)} papers left of {n_papers_before} which is {100*len(df_papers)/n_papers_before:.2f}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\david\\AppData\\Local\\Temp/ipykernel_11632/3790806285.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_papers[\"author_field\"][index] = authors_fields\n",
      "38072it [00:41, 913.57it/s] \n"
     ]
    }
   ],
   "source": [
    "# Now the time consuming part \n",
    "# Argment paper dataframe \n",
    "df_papers = argument_paper_dataframe(df_papers=df_papers, df_author=df_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 papers removed because there are more than 9 CSS authors. (0%)\n",
      "32257 papers removed because thier fields and authors are not in Quantitative Fields. (85%)\n",
      "There are 5650 papers left of 1078817 which is 0.52%\n"
     ]
    }
   ],
   "source": [
    "# Drop papers based on authors \n",
    "df_papers = generate_CCS_papers_2(df_papers, social_science_fields, quantitative_fields, verbose=True)\n",
    "\n",
    "print(f\"There are {len(df_papers)} papers left of {n_papers_before} which is {100*len(df_papers)/n_papers_before:.2f}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the agumentet dataframe \n",
    "pd.DataFrame.to_csv(df_papers, \"df_CSS_paper.csv\")\n",
    "\n",
    "# TODO Check how many unique authors have written these papers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print 10 top papers \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4eedd9fc418f36e2614580cbf31de2386521dabe9ec8a80375aa0fadc40a33bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
