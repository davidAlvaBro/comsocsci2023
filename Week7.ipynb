{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords')\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "text = PlaintextCorpusReader('my_data/', '.*')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "['My', 'name', 'is', 'August', ',', 'and', 'I', 'am', ...]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.words('test_text.txt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "with open('my_data/test_text.txt') as text_file:\n",
    "    raw = text_file.read()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(raw)\n",
    "#tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "#pattern = r\"[^\\w\\s]\"\n",
    "\n",
    "tokens = [token.lower() for token in tokens]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def remove_digits(l):\n",
    "    pattern = r'[0-9\\p{P}]'\n",
    "    l = [re.sub(pattern, '', token) for token in l]\n",
    "    return l"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "ename": "error",
     "evalue": "bad escape \\p at position 4",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[41], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m tokens \u001B[38;5;241m=\u001B[39m \u001B[43mremove_digits\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokens\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m tokens\n",
      "Cell \u001B[1;32mIn[40], line 3\u001B[0m, in \u001B[0;36mremove_digits\u001B[1;34m(l)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mremove_digits\u001B[39m(l):\n\u001B[0;32m      2\u001B[0m     pattern \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m[0-9\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mp\u001B[39m\u001B[38;5;132;01m{P}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m----> 3\u001B[0m     l \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[43mre\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msub\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpattern\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ml\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m l\n",
      "Cell \u001B[1;32mIn[40], line 3\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mremove_digits\u001B[39m(l):\n\u001B[0;32m      2\u001B[0m     pattern \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m[0-9\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mp\u001B[39m\u001B[38;5;132;01m{P}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m----> 3\u001B[0m     l \u001B[38;5;241m=\u001B[39m [\u001B[43mre\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msub\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpattern\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m token \u001B[38;5;129;01min\u001B[39;00m l]\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m l\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\re\\__init__.py:185\u001B[0m, in \u001B[0;36msub\u001B[1;34m(pattern, repl, string, count, flags)\u001B[0m\n\u001B[0;32m    178\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msub\u001B[39m(pattern, repl, string, count\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, flags\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m    179\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return the string obtained by replacing the leftmost\u001B[39;00m\n\u001B[0;32m    180\u001B[0m \u001B[38;5;124;03m    non-overlapping occurrences of the pattern in string by the\u001B[39;00m\n\u001B[0;32m    181\u001B[0m \u001B[38;5;124;03m    replacement repl.  repl can be either a string or a callable;\u001B[39;00m\n\u001B[0;32m    182\u001B[0m \u001B[38;5;124;03m    if a string, backslash escapes in it are processed.  If it is\u001B[39;00m\n\u001B[0;32m    183\u001B[0m \u001B[38;5;124;03m    a callable, it's passed the Match object and must return\u001B[39;00m\n\u001B[0;32m    184\u001B[0m \u001B[38;5;124;03m    a replacement string to be used.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 185\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_compile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpattern\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflags\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msub(repl, string, count)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\re\\__init__.py:294\u001B[0m, in \u001B[0;36m_compile\u001B[1;34m(pattern, flags)\u001B[0m\n\u001B[0;32m    288\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[0;32m    289\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe re.TEMPLATE/re.T flag is deprecated \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    290\u001B[0m               \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is an undocumented flag \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    291\u001B[0m               \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwithout an obvious purpose. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    292\u001B[0m               \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDon\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt use it.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    293\u001B[0m               \u001B[38;5;167;01mDeprecationWarning\u001B[39;00m)\n\u001B[1;32m--> 294\u001B[0m p \u001B[38;5;241m=\u001B[39m \u001B[43m_compiler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpattern\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflags\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    295\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (flags \u001B[38;5;241m&\u001B[39m DEBUG):\n\u001B[0;32m    296\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(_cache) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m _MAXCACHE:\n\u001B[0;32m    297\u001B[0m         \u001B[38;5;66;03m# Drop the oldest item\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\re\\_compiler.py:743\u001B[0m, in \u001B[0;36mcompile\u001B[1;34m(p, flags)\u001B[0m\n\u001B[0;32m    741\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m isstring(p):\n\u001B[0;32m    742\u001B[0m     pattern \u001B[38;5;241m=\u001B[39m p\n\u001B[1;32m--> 743\u001B[0m     p \u001B[38;5;241m=\u001B[39m \u001B[43m_parser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse\u001B[49m\u001B[43m(\u001B[49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflags\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    744\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    745\u001B[0m     pattern \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\re\\_parser.py:980\u001B[0m, in \u001B[0;36mparse\u001B[1;34m(str, flags, state)\u001B[0m\n\u001B[0;32m    977\u001B[0m state\u001B[38;5;241m.\u001B[39mflags \u001B[38;5;241m=\u001B[39m flags\n\u001B[0;32m    978\u001B[0m state\u001B[38;5;241m.\u001B[39mstr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m\n\u001B[1;32m--> 980\u001B[0m p \u001B[38;5;241m=\u001B[39m \u001B[43m_parse_sub\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflags\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m&\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mSRE_FLAG_VERBOSE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    981\u001B[0m p\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mflags \u001B[38;5;241m=\u001B[39m fix_flags(\u001B[38;5;28mstr\u001B[39m, p\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mflags)\n\u001B[0;32m    983\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m source\u001B[38;5;241m.\u001B[39mnext \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\re\\_parser.py:455\u001B[0m, in \u001B[0;36m_parse_sub\u001B[1;34m(source, state, verbose, nested)\u001B[0m\n\u001B[0;32m    453\u001B[0m start \u001B[38;5;241m=\u001B[39m source\u001B[38;5;241m.\u001B[39mtell()\n\u001B[0;32m    454\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 455\u001B[0m     itemsappend(\u001B[43m_parse\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnested\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    456\u001B[0m \u001B[43m                       \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mnested\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mitems\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    457\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m sourcematch(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m|\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    458\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\re\\_parser.py:568\u001B[0m, in \u001B[0;36m_parse\u001B[1;34m(source, state, verbose, nested, first)\u001B[0m\n\u001B[0;32m    566\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    567\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m this[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 568\u001B[0m     code1 \u001B[38;5;241m=\u001B[39m \u001B[43m_class_escape\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mthis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    569\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    570\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mset\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m this \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-&~|\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m source\u001B[38;5;241m.\u001B[39mnext \u001B[38;5;241m==\u001B[39m this:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\re\\_parser.py:361\u001B[0m, in \u001B[0;36m_class_escape\u001B[1;34m(source, escape)\u001B[0m\n\u001B[0;32m    359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(escape) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m    360\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m ASCIILETTERS:\n\u001B[1;32m--> 361\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m source\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbad escape \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m escape, \u001B[38;5;28mlen\u001B[39m(escape))\n\u001B[0;32m    362\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m LITERAL, \u001B[38;5;28mord\u001B[39m(escape[\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m    363\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n",
      "\u001B[1;31merror\u001B[0m: bad escape \\p at position 4"
     ]
    }
   ],
   "source": [
    "    tokens = remove_digits(tokens)\n",
    "tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "def clean_strings(strings):\n",
    "    cleaned_strings = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    for string in strings:\n",
    "        # Remove URLs\n",
    "        string = re.sub(r'http\\S+', '', string)\n",
    "\n",
    "        # Remove numbers\n",
    "        string = re.sub(r'[0-9]', '', string)\n",
    "\n",
    "        # Keep only what is not punctuation\n",
    "        string = re.sub(r'[^\\w\\s]', '', string)\n",
    "\n",
    "        # Remove stop words and moke them\n",
    "        if string not in stop_words: string = string.lower()\n",
    "\n",
    "        # Remove empty strings\n",
    "        if len(string):\n",
    "            cleaned_strings.append(string)\n",
    "\n",
    "    return cleaned_strings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'name', 'is', 'august', 'and', 'i', 'am', 'writing', 'this', 'to', 'test', 'different', 'functions', 'newline', 'is', 'here', 'in', 'line', 'two', 'and', 'i', 'will', 'have', 'one', 'in', 'a', 'second', 'as', 'well', 'third', 'line', 'can', 'test', 'if', 'we', 'can', 'find', 'multiple', 'lines']\n"
     ]
    }
   ],
   "source": [
    "print(clean_strings(tokens))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "df_abstract = pd.read_csv('my_data/df_CSS_paper_abstract.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35593it [01:59, 297.60it/s]\n",
      "0it [00:00, ?it/s]C:\\Users\\Libz\\AppData\\Local\\Temp\\ipykernel_15476\\4017611902.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_abstract['tokens'][i] = clean_tokens\n",
      "35593it [02:17, 258.20it/s]\n"
     ]
    }
   ],
   "source": [
    "cleaned_corpus = []\n",
    "df_abstract['tokens'] = None\n",
    "for i, row in tqdm(df_abstract.iterrows()):\n",
    "    abstract = row['abstract']\n",
    "    if type(abstract) == str:\n",
    "\n",
    "        tokens = nltk.word_tokenize(row['abstract'])\n",
    "        clean_tokens = clean_strings(tokens)\n",
    "        cleaned_corpus.append(clean_tokens)\n",
    "        df_abstract['tokens'][i] = clean_tokens\n",
    "    else:\n",
    "        cleaned_corpus.append(None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "graph = nx.read_graphml('my_data/CSS_graph.graphml')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "def louvain_communities(graph):\n",
    "    # Use the louvain method to find communities\n",
    "    partition = community.best_partition(graph) # community function that uses Louvain-algorithm\n",
    "\n",
    "    # Reformat the partitioning\n",
    "    communities = {}\n",
    "    for node, community_id in partition.items():\n",
    "        if community_id in communities:\n",
    "            communities[community_id].append(node)\n",
    "        else:\n",
    "            communities[community_id] = [node]\n",
    "\n",
    "    return list(communities.values())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "communities = np.load('my_data/Louvain_communities.npy', allow_pickle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "0        [the, term, linked, data, refers, to, a, set, ...\n1        [the, term, linked, data, refers, to, a, set, ...\n2        [the, term, linked, data, refers, to, a, set, ...\n3                                                     None\n4        [the, era, of, big, data, has, begun, computer...\n                               ...                        \n35588    [the, digitization, of, matrimonial, matchmaki...\n35589    [the, misuse, of, social, media, platforms, to...\n35590    [with, twitter, growing, as, a, preferred, cha...\n35591    [with, twitter, growing, as, a, preferred, cha...\n35592    [this, chapter, concludes, that, health, promo...\nName: tokens, Length: 35593, dtype: object"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_abstract['tokens']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "616it [00:17, 35.90it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[115], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m community_tokens \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m authorID \u001B[38;5;129;01min\u001B[39;00m community:\n\u001B[1;32m----> 7\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m authorID \u001B[38;5;129;01min\u001B[39;00m \u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mauthors\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m:\n\u001B[0;32m      8\u001B[0m         tokens \u001B[38;5;241m=\u001B[39m row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtokens\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      9\u001B[0m         community_tokens\u001B[38;5;241m.\u001B[39mappend(tokens)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:981\u001B[0m, in \u001B[0;36mSeries.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    978\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[key]\n\u001B[0;32m    980\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m key_is_scalar:\n\u001B[1;32m--> 981\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    983\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_hashable(key):\n\u001B[0;32m    984\u001B[0m     \u001B[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001B[39;00m\n\u001B[0;32m    985\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    986\u001B[0m         \u001B[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1090\u001B[0m, in \u001B[0;36mSeries._get_value\u001B[1;34m(self, label, takeable)\u001B[0m\n\u001B[0;32m   1088\u001B[0m \u001B[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001B[39;00m\n\u001B[0;32m   1089\u001B[0m loc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mget_loc(label)\n\u001B[1;32m-> 1090\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_values_for_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5934\u001B[0m, in \u001B[0;36mIndex._get_values_for_loc\u001B[1;34m(self, series, loc, key)\u001B[0m\n\u001B[0;32m   5929\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   5930\u001B[0m \u001B[38;5;124;03m    Should an integer key be treated as positional?\u001B[39;00m\n\u001B[0;32m   5931\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m   5932\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mholds_integer()\n\u001B[1;32m-> 5934\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_values_for_loc\u001B[39m(\u001B[38;5;28mself\u001B[39m, series: Series, loc, key):\n\u001B[0;32m   5935\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   5936\u001B[0m \u001B[38;5;124;03m    Do a positional lookup on the given Series, returning either a scalar\u001B[39;00m\n\u001B[0;32m   5937\u001B[0m \u001B[38;5;124;03m    or a Series.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   5941\u001B[0m \u001B[38;5;124;03m    key is included for MultiIndex compat.\u001B[39;00m\n\u001B[0;32m   5942\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m   5943\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_integer(loc):\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "all_communities = []\n",
    "#Test if pandas explode is more efficient\n",
    "# Den her kan gøre meget bedre tror jeg, skal bare lige tænke mig lidt om\n",
    "for i, row in tqdm(df_abstract.iterrows()):\n",
    "    for community in communities:\n",
    "        community_tokens = []\n",
    "        for authorID in community:\n",
    "            if authorID in row['authors']:\n",
    "                tokens = row['tokens']\n",
    "                community_tokens.append(tokens)\n",
    "        all_communities.append(community_tokens)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#list of unique tokens\n",
    "unique_tokens = list({token for sublist in all_communities for token in sublist})\n",
    "token_count_dict = {token: 0 for token in unique_tokens}\n",
    "for sublist in all_communities:\n",
    "    for token in sublist:\n",
    "        token_count_dict[token] += sublist.count(token)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
